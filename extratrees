import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.ensemble import ExtraTreesRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.datasets import make_regression  # Sample dataset generator
import matplotlib.pyplot as plt

# Assuming your data is in a file named 'your_data.csv'
file_path = '/content/silkboard.csv'

# Load your data into a Pandas DataFrame
df = pd.read_csv(file_path)
df=df.apply(pd.to_numeric,errors='coerce')

# Replace 'None' values with actual NaN values for easier handling
df.replace('None', pd.NA, inplace=True)

# Separating features and target variable
X = df.drop('PM2.5', axis=1)  # Features
y = df['PM2.5']  # Target variable

# Creating SimpleImputer instance to impute missing values with the mean
imputer = SimpleImputer(strategy='most_frequent')

# Creating SimpleImputer instance to impute missing values with the mean for y
imputer_y = SimpleImputer(strategy='most_frequent')

# Impute missing values in the features
X_imputed = imputer.fit_transform(X)

# Reshape y to a 2D array
y = y.values.reshape(-1, 1)
y_imputed = imputer_y.fit_transform(y)

# Generating sample dataset (you can replace this with your own dataset)
X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)

# Splitting the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_imputed, y_imputed, test_size=0.2, random_state=42)

# Create the Extra Trees Regressor
extra_trees = ExtraTreesRegressor(n_estimators=1200, max_depth=25, random_state=42)

# Fit the model on the training data
extra_trees.fit(X_train, y_train)

# Predict on the test set
predictions = extra_trees.predict(X_test)

# Calculate RMSE
rmse = np.sqrt(mean_squared_error(y_test, predictions))
print(f"Root Mean Squared Error (RMSE): {rmse}")

# Calculate R-squared
r2 = r2_score(y_test, predictions)
print(f"R-squared: {r2}")

# Calculate Mean Squared Error
mse = mean_squared_error(y_test, predictions)
print(f"Mean Squared Error (MSE): {mse}")

# Plotting histogram for predicted values
plt.figure(figsize=(8, 6))
plt.hist(predictions, bins=30, edgecolor='black')  # You can adjust the number of bins as needed
plt.xlabel('Predicted PM2.5 Values')
plt.ylabel('Frequency')
plt.title('Histogram of Predicted PM2.5 Values (Extra Trees Regression)')
plt.show()


RESULTS:
Root Mean Squared Error (RMSE): 5.119419444259394
R-squared: 0.9031638359337522
Mean Squared Error (MSE): 26.20845544626117

